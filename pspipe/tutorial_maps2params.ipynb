{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to generate the data needed for the simple map2parameter simulation. It\n",
    "generates the expected noise power spectra of the Simons Observatory (SO) large aperture telescope\n",
    "and the expected Planck white noise power spectra. It also generates beam files for SO and Planck.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib` magic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versions used for this tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "import pspipe\n",
    "import pspy\n",
    "import camb\n",
    "print(\"     Numpy :\", np.__version__)\n",
    "print(\"Matplotlib :\", mpl.__version__)\n",
    "print(\"    healpy :\", hp.__version__)\n",
    "print(\"     psipe :\", pspipe.__version__)\n",
    "print(\"      pspy :\", pspy.__version__)\n",
    "print(\"      camb :\", camb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use the Planck colormap as default *via* `pixell`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixell import colorize\n",
    "colorize.mpl_setdefault(\"planck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare simulation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipole range & experiment frequency channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations will be generated between $\\ell_text{min} = 2$ and $\\ell_\\text{max} = 10^4$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_min, ell_max = 2, 10000\n",
    "ell = np.arange(ell_min, ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computation of noise levels and beam harmonics, we will use the following frequency channels for\n",
    "SO and Planck experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {\n",
    "    \"LAT\": [27, 39, 93, 145, 225, 280],\n",
    "    \"Planck\": [100, 143, 217, 353]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see later, we will use less bands and much less multipoles for spectra computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoritical input spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [CAMB](https://camb.readthedocs.io/en/latest/) and a set of cosmological parameters, we can produce $C_\\ell$ for the different spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_params = {\n",
    "    \"H0\": 67.5,\n",
    "    \"As\": 1e-10*np.exp(3.044),\n",
    "    \"ombh2\": 0.02237,\n",
    "    \"omch2\": 0.1200,\n",
    "    \"ns\": 0.9649,\n",
    "    \"Alens\": 1.0,\n",
    "    \"tau\": 0.0544\n",
    "}\n",
    "pars = camb.set_params(**cosmo_params)\n",
    "pars.set_for_lmax(ell_max, lens_potential_accuracy=1)\n",
    "results = camb.get_results(pars)\n",
    "powers = results.get_cmb_power_spectra(pars, CMB_unit=\"muK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = [\"tt\", \"ee\", \"bb\", \"te\"]\n",
    "dls = {cl: powers[\"total\"][ell_min:ell_max, i]\n",
    "       for i, cl in enumerate(spectra)}\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(6, 8))\n",
    "axes[0].set_yscale(\"log\")\n",
    "for i, (spec, dl) in enumerate(dls.items()):\n",
    "    ax = axes[1] if spec == \"te\" else axes[0]\n",
    "    ax.plot(ell, dl, \"-C{}\".format(i), label=spec.upper())\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylabel(r\"$D_\\ell$\")\n",
    "    ax.legend()\n",
    "    axes[1].set_xlabel(r\"$\\ell$\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of experimental noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise levels in temperature and polarisation are stored within two dictionaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ell_t = {}\n",
    "n_ell_pol = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SO noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SO noise calculator to compute the expected noise in temperature and polarisation for\n",
    "which we have to specify a sensitivity mode (1: baseline, 2:goal), and a 40% fraction of sky to\n",
    "calculate the associated noise level. The outputs of the noise calculator followed an hardcoded\n",
    "sequence of cross frequencies that we explicitely write here within the `f_pairs_LAT`\n",
    "dictionary. Other missing cross frequencies are supposed to give a zero noise level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import so_noise_calculator_public_20180822 as noise_calc\n",
    "ell, n_ell_t_LAT, n_ell_pol_LAT, _ = noise_calc.Simons_Observatory_V3_LA_noise(sensitivity_mode=1,\n",
    "                                                                               f_sky=0.4,\n",
    "                                                                               ell_min=ell_min,\n",
    "                                                                               ell_max=ell_max,\n",
    "                                                                               delta_ell=1,\n",
    "                                                                               apply_beam_correction=False)\n",
    "\n",
    "from itertools import combinations_with_replacement as cwr\n",
    "for cross in cwr(frequencies[\"LAT\"], 2):\n",
    "    n_ell_t[\"LAT\", cross[0], cross[1]] = np.zeros_like(ell, dtype=np.float)\n",
    "    n_ell_pol[\"LAT\", cross[0], cross[1]] = np.zeros_like(ell, dtype=np.float)\n",
    "f_pairs_LAT = [(\"LAT\", 27, 27),\n",
    "               (\"LAT\", 39, 39),\n",
    "               (\"LAT\", 93, 93),\n",
    "               (\"LAT\", 145, 145),\n",
    "               (\"LAT\", 225, 225),\n",
    "               (\"LAT\", 280, 280),\n",
    "               (\"LAT\", 27, 39),\n",
    "               (\"LAT\", 93, 145),\n",
    "               (\"LAT\", 225, 280)]\n",
    "for i, f_pair in enumerate(f_pairs_LAT):\n",
    "  n_ell_t[f_pair] = n_ell_t_LAT[i]\n",
    "  n_ell_pol[f_pair] = n_ell_pol_LAT[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planck noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use information from the Table 4 of [https://arxiv.org/pdf/1807.06205.pdf](https://arxiv.org/pdf/1807.06205.pdf). Planck noise will\n",
    "be assumed to be white for these simulations and Planck standard deviations are in ÂµK.arcmin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross in cwr(frequencies[\"Planck\"], 2):\n",
    "    n_ell_t[\"Planck\", cross[0], cross[1]] = np.zeros_like(ell, dtype=np.float)\n",
    "    n_ell_pol[\"Planck\", cross[0], cross[1]] = np.zeros_like(ell, dtype=np.float)\n",
    "sigma_t = {\n",
    "    (\"Planck\", 100, 100): 77.4,\n",
    "    (\"Planck\", 143, 143): 33.0,\n",
    "    (\"Planck\", 217, 217): 46.8,\n",
    "    (\"Planck\", 353, 353): 153.6\n",
    "}\n",
    "for f_pair, sigma in sigma_t.items():\n",
    "  sigma_rad = np.deg2rad(sigma) / 60\n",
    "  n_ell_t[f_pair] = ell * 0 + sigma_rad**2\n",
    "\n",
    "sigma_pol = {\n",
    "    (\"Planck\", 100, 100): 117.6,\n",
    "    (\"Planck\", 143, 143): 70.2,\n",
    "    (\"Planck\", 217, 217): 105.0,\n",
    "    (\"Planck\", 353, 353): 438.6\n",
    "}\n",
    "for f_pair, sigma in sigma_pol.items():\n",
    "  sigma_rad = np.deg2rad(sigma) / 60\n",
    "  n_ell_pol[f_pair] = ell * 0 + sigma_rad**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of beam harmonics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's generate the beam harmonic transform for Planck and SO LAT. For Planck we will use\n",
    "information from the Table 4 of [https://arxiv.org/pdf/1807.06205.pdf](https://arxiv.org/pdf/1807.06205.pdf). For SO we use info from Table\n",
    "1 of [https://arxiv.org/pdf/1808.07445.pdf](https://arxiv.org/pdf/1808.07445.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_fwhm = {}\n",
    "beam_fwhm[\"LAT\", 27] = 7.4\n",
    "beam_fwhm[\"LAT\", 39] = 5.1\n",
    "beam_fwhm[\"LAT\", 93] = 2.2\n",
    "beam_fwhm[\"LAT\", 145] = 1.4\n",
    "beam_fwhm[\"LAT\", 225] = 1.0\n",
    "beam_fwhm[\"LAT\", 280] = 0.9\n",
    "\n",
    "beam_fwhm[\"Planck\", 100] = 9.68\n",
    "beam_fwhm[\"Planck\", 143] = 7.30\n",
    "beam_fwhm[\"Planck\", 217] = 5.02\n",
    "beam_fwhm[\"Planck\", 353] = 4.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store $b_\\ell$ and plot them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = {}\n",
    "from pspy import pspy_utils\n",
    "for exp, freqs in frequencies.items():\n",
    "  for freq in freqs:\n",
    "    idx = (exp, freq)\n",
    "    ell_bl, bl[idx] = pspy_utils.beam_from_fwhm(beam_fwhm[idx], ell_max)\n",
    "    plt.plot(ell_bl, bl[idx], label=\"{} - {} GHz\".format(exp, freq),\n",
    "             linestyle=\"-\" if exp == \"LAT\" else \"--\")\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "plt.ylabel(r\"$b_{\\ell}$\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting noise levels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given beam transform harmonics, we can now compare the noise power spectra with signal power spectra\n",
    "previously generated with [CAMB](https://camb.readthedocs.io/en/latest/). Let's plot everything together\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "grid = plt.GridSpec(2, 1, hspace=0.1, wspace=0)\n",
    "\n",
    "fac = ell * (ell + 1) / (2*np.pi)\n",
    "\n",
    "TT = plt.subplot(grid[0], xticklabels=[])\n",
    "TT.semilogy()\n",
    "TT.set_ylim(1, 10**5)\n",
    "TT.set_ylabel(r\"$N^{T}_{\\ell}$\")\n",
    "TT.plot(ell, dls[\"tt\"], \"k\")\n",
    "\n",
    "EE = plt.subplot(grid[1])\n",
    "EE.semilogy()\n",
    "EE.set_ylim(0.05, 10**3)\n",
    "EE.set_xlabel(r\"$\\ell$\")\n",
    "EE.set_ylabel(r\"$N^{P}_{\\ell}$\")\n",
    "EE.plot(ell, dls[\"ee\"], \"k\")\n",
    "\n",
    "for exp, freqs in frequencies.items():\n",
    "  for f1, f2 in cwr(freqs, 2):\n",
    "    name1, name2 = (exp, f1), (exp, f2)\n",
    "    name = (exp, f1, f2)\n",
    "    # Plot only non-zero noise\n",
    "    if not np.any(n_ell_t[name]): continue\n",
    "\n",
    "    TT.plot(ell, n_ell_t[name] * fac / (bl[name1] * bl[name2]), label=\"{} - {}x{} GHz\".format(*name),\n",
    "            linestyle=\"-\" if exp == \"LAT\" else \"--\")\n",
    "    EE.plot(ell, n_ell_pol[name] * fac / (bl[name1] * bl[name2]),\n",
    "            linestyle=\"-\" if exp == \"LAT\" else \"--\")\n",
    "\n",
    "TT.legend(loc=\"upper left\", bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a binning file made of 200 bins with an adaptative bin size. The output file has 3\n",
    "columns : $\\ell$<sub>min</sub>, $\\ell$<sub>max</sub>, $\\ell$<sub>mean</sub>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 200\n",
    "bin_size = np.empty(n_bins)\n",
    "bin_size[0] = 50\n",
    "bin_size[1:80] = 35\n",
    "bin_size[80:100] = 60\n",
    "bin_size[100:] = 100\n",
    "\n",
    "bin_min = 2\n",
    "bins = np.empty((n_bins, 3))\n",
    "for i, bs in enumerate(bin_size):\n",
    "    bin_max = bin_min + bs\n",
    "    bins[i] = bin_min, bin_max, np.mean([bin_min, bin_max])\n",
    "    bin_min += bs + 1\n",
    "\n",
    "binning_file = \"/tmp/binning.dat\"\n",
    "np.savetxt(binning_file, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of foregrounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce foreground levels, we use the `fgspectra` library\n",
    "[https://github.com/simonsobs/fgspectra](https://github.com/simonsobs/fgspectra). We only consider foreground components for the temperature\n",
    "cross-spectra and for the main LAT frequencies (93, 145 and 225 GHz).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies[\"LAT\"] = [93, 145, 225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foreground model is made of\n",
    "\n",
    "-   a kSZ and tSZ components,\n",
    "-   a cibp and a cibc components,\n",
    "-   a radio component\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = {\n",
    "    \"tt\": [\"kSZ\", \"cibp\", \"radio\", \"tSZ\", \"cibc\"],\n",
    "    \"te\": [],\n",
    "    \"ee\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the following foreground parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_params = {\n",
    "    \"a_tSZ\": 3.30,\n",
    "    \"a_kSZ\": 1.60,\n",
    "    \"a_p\": 6.90,\n",
    "    \"beta_p\": 2.08,\n",
    "    \"a_c\": 4.90,\n",
    "    \"beta_c\": 2.20,\n",
    "    \"n_CIBC\": 1.20,\n",
    "    \"a_s\": 3.10,\n",
    "    \"T_d\": 9.60\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foreground computation is done by the `mflike` likelihood in order to have a fully consistent way\n",
    "to simulate foregrounds and later, to reconstruct nuisance parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_model = {\n",
    "    \"normalisation\": {\n",
    "        \"nu_0\": 150.0,\n",
    "        \"ell_0\": 3000,\n",
    "        \"T_CMB\": 2.725\n",
    "    },\n",
    "    \"components\": components\n",
    "}\n",
    "from mflike import get_foreground_model\n",
    "fg_dict = get_foreground_model(fg_params, fg_model, [93, 145, 225], ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `TT`, we can plot foreground shape given cross frequencies and compare it to signal power spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"tt\"\n",
    "fig, axes = plt.subplots(3, 3, figsize=(9, 9), sharex=True, sharey=True)\n",
    "from itertools import product\n",
    "for i, cross in enumerate(product(frequencies[\"LAT\"], frequencies[\"LAT\"])):\n",
    "    idx = (i%3, i//3)\n",
    "    ax = axes[idx]\n",
    "    if idx in zip(*np.triu_indices(3, k=1)):\n",
    "        fig.delaxes(ax)\n",
    "        continue\n",
    "    for c in components[mode]:\n",
    "        ax.plot(ell, fg_dict[mode, c, cross[0], cross[1]])\n",
    "    ax.plot(ell, fg_dict[mode, \"all\", cross[0], cross[1]], color=\"black\")\n",
    "    ax.plot(ell, dls[mode], color=\"gray\")\n",
    "    ax.legend([], title=\"{}x{} GHz\".format(*cross))\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(10**-1, 10**4)\n",
    "\n",
    "for i in range(3):\n",
    "  axes[-1, i].set_xlabel(\"$\\ell$\")\n",
    "  axes[i, 0].set_ylabel(\"$D_\\ell$\")\n",
    "fig.legend([c for c in components[mode]] + [\"all\"], title=mode.upper(), bbox_to_anchor=(0.5,1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mode coupling matrices and window functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to compute the window functions, the mode coupling matrices (mcm) and the binning\n",
    "matrices (bbl) for the different frequency channels of the different CMB experiments. For\n",
    "illustrative purposes, everything will be done at low resolution namely `nside=1024` to reduce time\n",
    "computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask and window functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate window function by considering three masks:\n",
    "\n",
    "-   a galactic mask,\n",
    "-   a survey mask,\n",
    "-   a point source mask.\n",
    "\n",
    "Galactic and survey masks are pure `numpy` arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "galactic_mask = np.load(\"./masks/mask_equatorial_1024.npz\")[\"mask\"]\n",
    "survey_mask = np.load(\"./masks/survey_mask_1024.npz\")[\"mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point source mask is made of 100 holes each of 10 arcmin size that we apodize with a 'C1'\n",
    "apodization scheme and 0.3 degree size. We build it on top of a `HEALPIX` map with `nside=1024`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pspy import so_map\n",
    "mask = so_map.healpix_template(ncomp=1, nside=1024)\n",
    "mask.data[:] = 1\n",
    "from pspy import so_window\n",
    "mask = so_map.simulate_source_mask(mask, n_holes=100, hole_radius_arcmin=10)\n",
    "point_source_mask = so_window.create_apodization(mask, apo_type=\"C1\", apo_radius_degree=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot them next to each other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "hp.mollview(galactic_mask, title=\"Galactic\", sub=(1, 3, 1))\n",
    "hp.mollview(survey_mask, title=\"Survey\", sub=(1, 3, 2))\n",
    "hp.mollview(point_source_mask.data, title=\"Point source\", sub=(1, 3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the window by adding each mask (galactic and survey masks are first apodized with a\n",
    "5Â° beam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = so_map.healpix_template(ncomp=1, nside=1024)\n",
    "window.data[:] = 1\n",
    "window.data *= galactic_mask.data\n",
    "window.data *= survey_mask.data\n",
    "window = so_window.create_apodization(window, apo_type=\"C1\", apo_radius_degree=5)\n",
    "window.data *= point_source_mask.data\n",
    "\n",
    "hp.mollview(window.data, title=\"Window function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode coupling matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step consists to compute the mode coupling matrices and binning matrices for the different\n",
    "cross spectra given the window function and the beam harmonics transform computed above. We only\n",
    "consider LAT experiment with the three main frequency channels.\n",
    "\n",
    "For spin 0 and 2 the window need to be a tuple made of two objects: the window used for spin 0 and\n",
    "the one used for spin 2. Nevertheless, within this simple notebook, the window functions are the\n",
    "same over the different frequency. Consequently, the `win1` and `win2` arguments of\n",
    "`so_mcm.mcm_and_bbl_spin0and2` function are the same and consists of a tuple of two window\n",
    "function. In more general case, this will be different.\n",
    "\n",
    "For each cross spectra *i.e.* `LAT_93xLAT_93`&#x2026; we store the mcm and bbl matrices as follow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pspy import so_mcm\n",
    "mbb_inv, bbl = {}, {}\n",
    "for f1, f2 in cwr(frequencies[\"LAT\"], 2):\n",
    "  name = \"LAT{}xLAT{}\".format(f1, f2)\n",
    "  print(\"Processing {}...\".format(name))\n",
    "  mbb_inv[name], bbl[name] = so_mcm.mcm_and_bbl_spin0and2(win1=(window, window),\n",
    "                                                          win2=(window, window),\n",
    "                                                          bl1=(bl[\"LAT\", f1], bl[\"LAT\", f1]),\n",
    "                                                          bl2=(bl[\"LAT\", f2], bl[\"LAT\", f2]),\n",
    "                                                          binning_file=binning_file,\n",
    "                                                          niter=3,\n",
    "                                                          type=\"Dl\",\n",
    "                                                          lmax=2000,\n",
    "                                                          lmax_pad=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the $M_{bb}^{-1}$ matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mcm(spin):\n",
    "    def _get_min_max():\n",
    "        a = np.concatenate([np.log10(np.abs(v2+1e-15)) for k1, v1 in mbb_inv.items()\n",
    "                            for k2, v2 in v1.items() if k2 == spin])\n",
    "        return np.min(a), np.max(a)\n",
    "    vmin, vmax = _get_min_max()\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9), sharex=True, sharey=True)\n",
    "    from itertools import product\n",
    "    for i, cross in enumerate(product(frequencies[\"LAT\"], frequencies[\"LAT\"])):\n",
    "        idx = (i%3, i//3)\n",
    "        ax = axes[idx]\n",
    "        if idx in zip(*np.triu_indices(3, k=1)):\n",
    "            fig.delaxes(ax)\n",
    "            continue\n",
    "        name = \"LAT{}xLAT{}\".format(*cross)\n",
    "        mcm = mbb_inv[name][spin]\n",
    "        im = ax.imshow(np.log10(np.abs(mcm)), vmin=vmin, vmax=vmax)\n",
    "        ax.legend([], title=\"LAT {}x{} GHz\".format(*cross))\n",
    "    plt.tight_layout()\n",
    "    # Now adding the colorbar\n",
    "    cbaxes = fig.add_axes([0.8, 0.4, 0.015, 0.5])\n",
    "    cb = plt.colorbar(im, cax=cbaxes)\n",
    "    cb.set_label(\"$\\log$(%s)\" % spin)\n",
    "plot_mcm(spin=\"spin0xspin0\")\n",
    "plot_mcm(spin=\"spin0xspin2\")\n",
    "plot_mcm(spin=\"spin2xspin2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the diagonal terms of the $M_{bb}^{-1}$ for the different spin combinations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(12, 8), sharey=\"row\", sharex=\"col\")\n",
    "for cross, spins in mbb_inv.items():\n",
    "    for i, spin in enumerate([\"spin0xspin0\", \"spin0xspin2\", \"spin2xspin2\"]):\n",
    "        for k in [-1, 0, +1]:\n",
    "            if i == 0:\n",
    "              axes[k+1, i].legend([], title=\"diagonal k = {}\".format(k), loc=\"upper left\")\n",
    "            axes[k+1, i].plot(np.diag(spins[spin], k=k), label=cross)\n",
    "\n",
    "        axes[0, i].set_title(spin)\n",
    "    axes[0, -1].legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of simulations and power spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will now generate the simulations and compute their power spectra. We will\n",
    "consider two data splits and thus simulate experimental noise for both set. Given the data split we\n",
    "will finally compute the auto and cross spectra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power spectra matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a foreground matrix from the foreground power spectra computed in previous\n",
    "section. The final matrix will have a `[nfreq, nfreq, ell]` shape to get correlated foregrounds over\n",
    "different frequency channels and everything must be in raw-$C_\\ell$ *i.e.* we multiply foreground\n",
    "value by $2\\pi/(\\ell(\\ell+1)$. Only foregrounds for temperature are considered.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfreqs = len(frequencies[\"LAT\"])\n",
    "ps_fg = np.zeros((nfreqs, nfreqs, ell_max))\n",
    "for i, cross in enumerate(product(frequencies[\"LAT\"], frequencies[\"LAT\"])):\n",
    "  fg_all = fg_dict[\"tt\", \"all\", cross[0], cross[1]] * 2 * np.pi / (ell * (ell + 1))\n",
    "  ps_fg[i%nfreqs, i//nfreqs, ell_min:] = fg_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do the same for the noise power spectra both in temperature and polarisation given that we\n",
    "only consider here the LAT experiment. We basically cut noise below `ell_cut=30` since noise curves\n",
    "diverge at low multipole and we set the noise level to zero below this value. We also have to take\n",
    "into account the number of data splits and multiply the noise levels by this value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_cut = 30\n",
    "n_splits = 2\n",
    "ps_noise_t = np.zeros((nfreqs, nfreqs, ell_max))\n",
    "ps_noise_pol = np.zeros((nfreqs, nfreqs, ell_max))\n",
    "for i, cross in enumerate(product(frequencies[\"LAT\"], frequencies[\"LAT\"])):\n",
    "  idx = (\"LAT\", cross[0], cross[1])\n",
    "  if idx not in n_ell_t:\n",
    "    idx = (\"LAT\", cross[1], cross[0])\n",
    "  ps_noise_t[i%nfreqs, i//nfreqs, ell_cut:] = n_ell_t[idx][ell_cut-ell_min:] * n_splits\n",
    "  ps_noise_pol[i%nfreqs, i//nfreqs, ell_cut:] = n_ell_pol[idx][ell_cut-ell_min:] * n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the CMB power spectra matrix were row and columns correspond to (T, E, B)\n",
    "spectra: the final matrix has a $3\\times3\\times\\ell$ shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixell import powspec\n",
    "cls = powers[\"total\"][:ell_max].T.copy()\n",
    "cls[:, ell_min:] *= (2*np.pi)/(ell*(ell+1))\n",
    "ps_cmb = powspec.sym_expand(cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alm computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the power spectra for CMB, noise and foregrounds, we can compute the associated\n",
    "alm coefficients up to &ell;<sub>max</sub> = 6000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixell import curvedsky\n",
    "cmb_alms = curvedsky.rand_alm(ps_cmb, lmax=2000)\n",
    "fg_alms = curvedsky.rand_alm(ps_fg, lmax=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to generate realistic simulations by adding the foregrounds and noise to CMB\n",
    "data/alms. Foregrounds are only added for temperature (so far). We also have to \"blur\" the\n",
    "simulation given the beam computed in previous section. Finally we project everything onto a `HEALPIX`\n",
    "map with `nside=1024` corresponding to the maximum $\\ell$ value of 2000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pspy import so_map, sph_tools\n",
    "template = so_map.healpix_template(ncomp=3, nside=1024)\n",
    "maps = {\"TEB\": sph_tools.alm2map(cmb_alms, template.copy())}\n",
    "for i, freq in enumerate(frequencies[\"LAT\"]):\n",
    "  sim_alms = cmb_alms.copy()\n",
    "  sim_alms[0] += fg_alms[i]\n",
    "  for alm in sim_alms:\n",
    "    hp.almxfl(alm, bl[\"LAT\", freq], inplace=True)\n",
    "\n",
    "  for k in range(n_splits):\n",
    "    split_alms = sim_alms.copy()\n",
    "    split_alms[0] += curvedsky.rand_alm(ps_noise_t, lmax=2000)[i]\n",
    "    split_alms[1] += curvedsky.rand_alm(ps_noise_pol, lmax=2000)[i]\n",
    "    split_alms[2] += curvedsky.rand_alm(ps_noise_pol, lmax=2000)[i]\n",
    "    from pspy import sph_tools\n",
    "    maps[\"LAT\", freq, k] = sph_tools.alm2map(split_alms, template.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the maps associated to each frequency splits and let's compare it to the original CMB\n",
    "map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale color maps\n",
    "vmins = [np.min([m.data[i] for m in maps.values()]) for i in range(3)]\n",
    "vmaxs = [np.max([m.data[i] for m in maps.values()]) for i in range(3)]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(maps), ncols=3, figsize=(15, 21))\n",
    "axes = axes.flatten()\n",
    "iax = 0\n",
    "for k, v in maps.items():\n",
    "  for j in range(3):\n",
    "      plt.axes(axes[iax])\n",
    "      if isinstance(k, tuple):\n",
    "        title = \"{} GHz - split {}\".format(k[1], k[2])\n",
    "        plt.text(0.5, 1, title)\n",
    "      else:\n",
    "        title = \"{}\".format(k[j])\n",
    "        plt.text(0, 0.5, title)\n",
    "      hp.mollview(v.data[j], title=None, hold=True, min=vmins[j], max=vmaxs[j], cbar=False)\n",
    "      iax += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

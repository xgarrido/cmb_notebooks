#+TITLE: LAT Multi-Frequency Likelihood analysis
#+PROPERTY: header-args:jupyter-python :session mflike
#+PROPERTY: header-args :exports both
#+PROPERTY: header-args :tangle mflike_analysis.py

* Preamble
This notebook make use of [[https://getdist.readthedocs.io/en/latest/][GetDist]] python package to plot and to analyse MCMC samples.
#+BEGIN_SRC jupyter-python
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np
#+END_SRC

#+RESULTS:

Print versions used
#+BEGIN_SRC jupyter-python
  import matplotlib
  import getdist
  getdist.chains.print_load_details = False

  print("     Numpy :", np.__version__)
  print("Matplotlib :", matplotlib.__version__)
  print("   GetDist :", getdist.__version__)
#+END_SRC

#+RESULTS:
:      Numpy : 1.19.0
: Matplotlib : 3.2.2
:    GetDist : 1.1.2

* Definitions
Define CMB & nuisance parameter names.
#+BEGIN_SRC jupyter-python :results none
  cosmo_params = [
      "cosmomc_theta",
      "logA",
      "ns",
      "ombh2",
      "omch2",
      "H0",
      "Alens",
      "tau"
  ]
  nuisance_params = [
      "a_tSZ",
      "a_kSZ",
      "a_p",
      "beta_p",
      "a_c",
      "beta_c",
      "a_s",
      # "n_CIBC",
      # "T_d"
  ]
#+END_SRC

* MCMC chains
Let's plot the chains size for all the simulations
#+BEGIN_SRC jupyter-python
  import glob
  nsim = 120
  nchains = {i: [] for i in range(nsim)}
  for i in range(nsim):
      chain_dir_tmpl = "./data/so_likelihood_sacc_lsst/sim_{}/mcmc.?.txt"
      files = sorted(glob.glob(chain_dir_tmpl.format(i)))
      nchains[i] += [sum(1 for line in open(f)) for f in files]
      nchains[i] += [sum(nchains[i])]

  from tabulate import tabulate
  print(tabulate([(k, *v) for k, v in nchains.items()],
                 headers=["Sim."] + ["mcmc {}".format(i) for i in range(1, 5)] + ["total"],
                 tablefmt="orgtbl"))
#+END_SRC

#+RESULTS:
#+begin_example
  |   Sim. |   mcmc 1 |   mcmc 2 |   mcmc 3 |   mcmc 4 |   total |
  |--------+----------+----------+----------+----------+---------|
  |      0 |     4601 |     4768 |     1720 |     3837 |   14926 |
  |      1 |     1722 |      736 |     3982 |     1596 |    8036 |
  |      2 |     4833 |     2276 |     4070 |     1804 |   12983 |
  |      3 |     4070 |     4280 |     1207 |     2812 |   12369 |
  |      4 |     4104 |     1878 |     3520 |     2286 |   11788 |
  |      5 |     3562 |     4099 |     1306 |     3967 |   12934 |
  |      6 |     3978 |     1939 |     1095 |     1213 |    8225 |
  |      7 |     1108 |     2185 |      917 |     2003 |    6213 |
  |      8 |     4522 |     4463 |     3774 |     4142 |   16901 |
  |      9 |     2527 |     4168 |     1673 |     2465 |   10833 |
  |     10 |     4455 |     4229 |     3983 |     1175 |   13842 |
  |     11 |     3845 |     1429 |     1265 |     4114 |   10653 |
  |     12 |     3884 |     2121 |     4249 |     2978 |   13232 |
  |     13 |     1152 |     1305 |     4315 |     1227 |    7999 |
  |     14 |     4127 |     1637 |     1551 |     1230 |    8545 |
  |     15 |     1133 |     1260 |     2689 |     1579 |    6661 |
  |     16 |     2160 |     1920 |     1511 |     3329 |    8920 |
  |     17 |     4144 |     1029 |     4110 |     4039 |   13322 |
  |     18 |     3682 |     3564 |     2345 |     3783 |   13374 |
  |     19 |     1768 |     2495 |     3926 |     4195 |   12384 |
  |     20 |     3847 |      610 |     3924 |     1196 |    9577 |
  |     21 |     4051 |     4291 |     4597 |     4429 |   17368 |
  |     22 |     4373 |     4115 |     2993 |     3623 |   15104 |
  |     23 |     3784 |     1303 |     1414 |     5464 |   11965 |
  |     24 |     1875 |     1253 |     2319 |     4075 |    9522 |
  |     25 |     2149 |     3850 |      819 |     1616 |    8434 |
  |     26 |     4298 |     3954 |     4218 |     4305 |   16775 |
  |     27 |     4329 |     2333 |      974 |     3869 |   11505 |
  |     28 |     3232 |     2074 |     1585 |     2509 |    9400 |
  |     29 |     1414 |     2038 |     2211 |     4561 |   10224 |
  |     30 |     4619 |     1552 |     1877 |     4132 |   12180 |
  |     31 |     2061 |     4502 |     1176 |     1203 |    8942 |
  |     32 |     1149 |     1332 |     1450 |     1799 |    5730 |
  |     33 |     1702 |     3769 |     1123 |     4734 |   11328 |
  |     34 |     1308 |     4156 |     1149 |     1294 |    7907 |
  |     35 |      934 |     2438 |     4703 |     1831 |    9906 |
  |     36 |     1237 |     3841 |     4949 |     3915 |   13942 |
  |     37 |     2007 |     3361 |     1215 |     4114 |   10697 |
  |     38 |     4246 |     1792 |     3672 |     1537 |   11247 |
  |     39 |     4411 |     3927 |     4144 |     1124 |   13606 |
  |     40 |     3608 |     4284 |     1571 |     4090 |   13553 |
  |     41 |     1807 |     4697 |     1388 |     1227 |    9119 |
  |     42 |     4244 |     1235 |     1752 |     4405 |   11636 |
  |     43 |     1477 |     1874 |     1928 |      699 |    5978 |
  |     44 |     4491 |     1314 |     2991 |     4359 |   13155 |
  |     45 |     3503 |     3738 |     3960 |     4236 |   15437 |
  |     46 |     2277 |     4116 |     3807 |      573 |   10773 |
  |     47 |     3163 |     1330 |     1080 |     4037 |    9610 |
  |     48 |     3320 |     3717 |     1890 |     4497 |   13424 |
  |     49 |     5597 |     2336 |     4084 |     1229 |   13246 |
  |     50 |     1056 |     4078 |     3497 |     1520 |   10151 |
  |     51 |     4437 |     1104 |     3440 |     1740 |   10721 |
  |     52 |     3907 |     3656 |     1424 |     2381 |   11368 |
  |     53 |     2123 |     1554 |     3666 |     4871 |   12214 |
  |     54 |     2139 |     2085 |     1432 |     1178 |    6834 |
  |     55 |     1782 |     3794 |     1111 |     2618 |    9305 |
  |     56 |     2364 |     3972 |     1454 |     1575 |    9365 |
  |     57 |      940 |     1573 |     1035 |     3920 |    7468 |
  |     58 |     4410 |     4481 |     1692 |     1742 |   12325 |
  |     59 |     3337 |     4134 |     3846 |     1164 |   12481 |
  |     60 |     4866 |     3864 |     4357 |     4275 |   17362 |
  |     61 |     1497 |     3555 |     3627 |     1552 |   10231 |
  |     62 |     4012 |     4005 |      613 |      789 |    9419 |
  |     63 |      584 |     1166 |     1108 |     4270 |    7128 |
  |     64 |     1043 |     1686 |     1653 |     3864 |    8246 |
  |     65 |     2832 |     4182 |     2535 |     4318 |   13867 |
  |     66 |     3674 |     4248 |     2870 |     1811 |   12603 |
  |     67 |     4184 |     4699 |     4875 |     1564 |   15322 |
  |     68 |     1444 |     3994 |     1347 |     2932 |    9717 |
  |     69 |     4557 |     4321 |     1597 |     3638 |   14113 |
  |     70 |     1467 |     1105 |     1225 |     3805 |    7602 |
  |     71 |      620 |     1791 |     1678 |     1291 |    5380 |
  |     72 |     1451 |     1173 |     3778 |     4224 |   10626 |
  |     73 |     4334 |     3770 |     1284 |     4212 |   13600 |
  |     74 |     3623 |     4246 |     1051 |     3972 |   12892 |
  |     75 |     3615 |     4309 |     4155 |     4175 |   16254 |
  |     76 |     4085 |     1317 |     3610 |     4435 |   13447 |
  |     77 |     3576 |     1372 |     1631 |     4058 |   10637 |
  |     78 |     4504 |     3754 |     2145 |     3876 |   14279 |
  |     79 |     1348 |     4599 |     4373 |     2747 |   13067 |
  |     80 |      560 |     2357 |     3739 |     1665 |    8321 |
  |     81 |     4114 |      810 |     2179 |     4573 |   11676 |
  |     82 |     2510 |     1791 |     2461 |     1675 |    8437 |
  |     83 |     1662 |     1171 |     1356 |     4042 |    8231 |
  |     84 |     1055 |     4240 |     2058 |     4047 |   11400 |
  |     85 |     4864 |     1554 |     1270 |     2529 |   10217 |
  |     86 |     2363 |     3081 |     1143 |     1396 |    7983 |
  |     87 |     3567 |     2110 |     2252 |     4395 |   12324 |
  |     88 |     1675 |     2575 |     4715 |     1105 |   10070 |
  |     89 |     3977 |     2045 |     3821 |     3516 |   13359 |
  |     90 |      961 |     2960 |     2996 |     4174 |   11091 |
  |     91 |     4044 |     1244 |     3883 |     4148 |   13319 |
  |     92 |     4695 |     1793 |     4005 |     1171 |   11664 |
  |     93 |     2359 |      688 |     4029 |     4646 |   11722 |
  |     94 |     2142 |     2091 |     2406 |     1231 |    7870 |
  |     95 |     1079 |     1114 |     3667 |     1218 |    7078 |
  |     96 |     3759 |     1070 |     2307 |     4447 |   11583 |
  |     97 |     1495 |     3736 |     3729 |     1942 |   10902 |
  |     98 |     3833 |     1065 |     1920 |     1668 |    8486 |
  |     99 |     1503 |     2385 |     4204 |     3140 |   11232 |
  |    100 |     3659 |      996 |     3065 |     1566 |    9286 |
  |    101 |     1520 |     3686 |     1879 |     4076 |   11161 |
  |    102 |     1263 |     1082 |     4022 |     2430 |    8797 |
  |    103 |      964 |     3455 |     3229 |     1706 |    9354 |
  |    104 |     1247 |     3588 |     3696 |     4228 |   12759 |
  |    105 |     2014 |      852 |     1154 |     3064 |    7084 |
  |    106 |     1618 |     4216 |     1247 |     4098 |   11179 |
  |    107 |     1198 |     2006 |     1508 |     1096 |    5808 |
  |    108 |      721 |     4149 |     3465 |     1248 |    9583 |
  |    109 |     4516 |     4028 |     1267 |     1260 |   11071 |
  |    110 |     3668 |     4457 |     3700 |     2923 |   14748 |
  |    111 |     3599 |     1873 |     2064 |     1266 |    8802 |
  |    112 |     2469 |     2279 |     1470 |     1621 |    7839 |
  |    113 |     4167 |     3966 |     4226 |     1603 |   13962 |
  |    114 |     4498 |     2471 |     1924 |     1596 |   10489 |
  |    115 |     1285 |     1016 |     1552 |     2818 |    6671 |
  |    116 |     3685 |     1604 |     4004 |     4019 |   13312 |
  |    117 |     1176 |     1270 |      821 |     2453 |    5720 |
  |    118 |     2021 |     3954 |     4103 |     1006 |   11084 |
  |    119 |     1266 |     1197 |     3869 |     4570 |   10902 |
#+end_example


Have a look at how chains evolve with time and check convergence or not.
#+BEGIN_SRC jupyter-python :results none
  def plot_chains(file_root, params, nrow=None, ncol=None):
    import glob
    files = sorted(glob.glob(file_root + ".?.txt"))

    nrow = len(params)//2 if nrow is None else nrow
    ncol = len(params)//2 if ncol is None else ncol
    plt.figure(figsize=(15, 10))
    ax = [plt.subplot(nrow, ncol, i+1) for i in range(len(params))]

    # Loop over files independently
    for f in files:
      from getdist import loadMCSamples
      sample = loadMCSamples(f[:-4])
      color = "C{}".format(f.split(".")[-2])

      # Get param values
      values = sample.getParams()

      # Get associated LaTeX labels
      labels = sample.paramNames.parsWithNames(params)
      for i, p in enumerate(params):
        ax[i].set_ylabel(labels[i].latexLabel())
        ax[i].plot(getattr(values, p), alpha=0.75, color=color)
    plt.tight_layout()
#+END_SRC

Plot chains for the CMB & nuisance parameters given a simulation id (up to 100)
#+BEGIN_SRC jupyter-python
  # plot_chains(chains, params=cosmo_params+nuisance_params, ncol=4)
  sim_id = 10
  chains = "./data/so_likelihood_sacc_lsst/sim_{}/mcmc".format(sim_id)
  plot_chains(chains, params=cosmo_params+nuisance_params, ncol=4)
#+END_SRC

#+RESULTS:
:RESULTS:
: WARNING:root:outlier fraction 6.0157612945918305e-05
: WARNING:root:outlier fraction 0.001507032819825854
[[file:./.ob-jupyter/42fd90ff7148ee95fe1e0146b787ff24ebbb0c96.png]]
:END:

* MCMC distributions

#+BEGIN_SRC jupyter-python :results none
  inputs = {
      "cosmomc_theta": 0.0104085,
      "logA": 3.044,
      "ombh2": 0.02237,
      "omch2": 0.1200,
      "ns": 0.9649,
      "Alens": 1.0,
      "tau": 0.0544,
      "H0": 67.36,
      "a_tSZ": 3.30,
      "a_kSZ": 1.60,
      "a_p": 6.90,
      "beta_p": 2.08,
      "a_c": 4.90,
      "beta_c": 2.20,
      "n_CIBC": 1.20,
      "a_s": 3.10,
      "T_d": 9.60
  }
#+END_SRC

Function to plot (mean, std) for all the simulations given input value and Fisher variances.
#+BEGIN_SRC jupyter-python :results none
  def plot_sim_results(params, samples, color="C0"):
      fig, ax = plt.subplots(1, len(params), sharey=True, figsize=(20, 7))
      plt.subplots_adjust(hspace=0, wspace=0.15)
      plt.yticks([])

      chi2s = np.empty((len(params), len(samples)))
      values = np.zeros((len(params), len(samples)))
      weights = np.zeros((len(params), len(samples)))
      for i, sample in enumerate(samples):
          marge = sample.getMargeStats()
          for j, name in enumerate(params):
              par = marge.parWithName(name)
              x, xerr = par.mean, par.err
              markers, caps, bars = ax[j].errorbar(x, i, xerr=xerr, fmt="o{}".format(color),
                                                   ecolor=color, elinewidth=3)
              [bar.set_alpha(0.5) for bar in bars]
              chi2s[j, i] = ((x - inputs[name])/xerr)**2
              values[j, i] = x
              weights[j, i] = 1/xerr**2

      # Customize axes and labels
      for j, name in enumerate(params):
          ax[j].spines["right"].set_color(None)
          ax[j].spines["top"].set_color(None)
          ax[j].tick_params(bottom="off")
          label = samples[0].getLatex(params)[0][j]
          ax[j].set_xlabel(r"${}$".format(label))
          x = inputs[name]
          mu = np.average(values[j], weights=weights[j])
          # sigma = np.sqrt(np.average((values[j]-mu)**2, weights=weights[j]))
          sigma = np.mean(np.sqrt(1/weights[j]))
          ax[j].spines["left"].set_position(("data", x))
          ax[j].axvline(mu, color=color, linestyle="--")
          # sigma = fisher[name]
          # mu = x
          if sigma:
              ax[j].axvspan((mu - sigma), (mu + sigma), color="gray", alpha=0.15)
          from scipy.stats import chi2
          ax[j].set_title("$P(\chi^2)$ = {0:.3f}".format(
              chi2.sf(np.sum(chi2s[j]), len(chi2s[j]))))

      return values, weights
#+END_SRC

Function to plot all the KDE distributions of parameters
#+BEGIN_SRC jupyter-python :results none
  def plot_sim_distribution(params, samples, values, weights, nx=None, with_point=False):
      from getdist import plots
      g = plots.get_subplot_plotter(subplot_size=3, subplot_size_ratio=1.2)
      nsamples = len(samples)
      g.settings.line_styles = nsamples*["-0.6"]
      nx = len(params) if nx is None else nx
      g.plots_1d(samples, params, nx=nx, share_y=True, legend_labels=[], lws=2)
      for i, ax in enumerate(g.subplots.flatten()):
          if not ax: continue
          xmin, xmax, ymin, ymax = ax.axis()
          x = np.linspace(xmin, xmax, 1000)
          mu = np.average(values[i], weights=weights[i])
          # sigma = np.sqrt(np.average((values[i]-mu)**2, weights=weights[i]))
          sigma = np.mean(np.sqrt(1/weights[i]))
          from scipy.stats import norm
          ax.plot(x, sigma*np.sqrt(2*np.pi)*norm.pdf(x, mu, sigma), color="black", lw=3)
          ax.axvline(inputs[params[i]], color="red", lw=3)
          # ax.set_xlim(inputs[params[i]]-15*sigma, inputs[params[i]]+15*sigma)
          if with_point:
              for j in range(nsamples):
                  ax.errorbar(values[i, j], 1/nsamples*j, xerr=np.sqrt(1/weights[i, j]), fmt="ok", ecolor="black", zorder=3)
          legend = ax.legend([])
          legend.set_title(r"$\frac{{{:.1f}\,\sigma}}{{\sqrt{{N_{{\rm sim}}}}}}$".format(
              (mu-inputs[params[i]])/sigma*np.sqrt(len(values[i]))), prop={"size": 16})
#+END_SRC

Load the different samples
#+BEGIN_SRC jupyter-python :results none
  from getdist import loadMCSamples
  samples = [loadMCSamples("./data/so_likelihood_sacc_lsst/sim_{}/mcmc".format(sim_id),
                           settings={"ignore_rows": 0.4}) for sim_id in range(120)]
#+END_SRC

** CMB parameters
#+BEGIN_SRC jupyter-python
  pvalues, pweights = plot_sim_results(cosmo_params, samples)
#+END_SRC

#+RESULTS:
:RESULTS:
#+begin_example
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior
  WARNING:root:fine_bins not large enough to well sample smoothing scale - minuslogprior__0
#+end_example
[[file:./.ob-jupyter/2c2d794e9d3b5f49447b93f003258464b55811d0.png]]
:END:


#+BEGIN_SRC jupyter-python
  plot_sim_distribution(cosmo_params, samples, pvalues, pweights, nx=4, with_point=False)
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/2f51c303b8fe7c74e708f981083331b1686aa4ef.png]]

** Nuisance parameters
#+BEGIN_SRC jupyter-python
  nvalues, nweights = plot_sim_results(nuisance_params, samples, color="C4")
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/bb9c6be80a0f8e5f72159232c4c059d3836bfd4e.png]]


#+BEGIN_SRC jupyter-python
  plot_sim_distribution(nuisance_params, samples, nvalues, nweights, nx=4, with_point=False)
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/b5af9d061060d1ceb353a3cf6a909f4c79705d43.png]]
* Miscellaneous
** Triangle plot
Define global plot settings
#+BEGIN_SRC jupyter-python :results none
  from getdist.plots import GetDistPlotSettings
  plot_settings = GetDistPlotSettings()
  plot_settings.num_plot_contours = 3
  plot_settings.solid_colors = "tab10"
  plot_settings.line_styles = "tab10"
  plot_settings.legend_fontsize = 15
#+END_SRC

Show input values
#+BEGIN_SRC jupyter-python :results none
  def show_input(g, params):
      for i, p in enumerate(params):
          x = inputs.get(p, np.nan)
          kwargs = dict(color="gray", ls="--", lw=1)
          for ax in g.subplots[:,i]:
              if ax: ax.axvline(x, **kwargs)
          for ax in g.subplots[i,:i]:
              if ax: ax.axhline(x, **kwargs)
#+END_SRC

Load MCMC samples
#+BEGIN_SRC jupyter-python :results none
  sim_id = 0
  from getdist import loadMCSamples
  samples = [loadMCSamples("./data/so_likelihood_sacc/sim_{}_{}/mcmc".format(spec, sim_id),
                           settings={"ignore_rows": 0.4}) for spec in ["tt", "ee", "te", "ttteee"]]
#+END_SRC

Plot posteriors distributions of CMB parameters
#+BEGIN_SRC jupyter-python
  from getdist import plots
  g = plots.get_subplot_plotter(settings=plot_settings)
  colors = ["C2", "C1", "C0", "C3"]
  g.triangle_plot(samples, cosmo_params,
                  filled=True, legend_labels=["TT", "EE", "TE", "TT, TE, EE"],
                  colors=colors, diag1d_kwargs={"colors": colors})
  # Show input value
  show_input(g, cosmo_params)
  # Show prior on tau
  ax = g.subplots[-1, -1]
  xmin, xmax, ymin, ymax = ax.axis()
  x = np.linspace(xmin, xmax, 100)
  from scipy.stats import norm
  ax.plot(x, 0.018*norm.pdf(x, 0.054, 0.0073), color="gray", ls="--", label=r"$\tau$ prior")
  ax.legend(loc="upper left", bbox_to_anchor=(1,1));
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/1a8b44ef486d245c3500eb31981a286ef2967b75.png]]

#+BEGIN_SRC jupyter-python
  g.triangle_plot([samples[0], samples[-1]], nuisance_params,
                  filled=True, legend_labels=["TT", "TT, TE, EE"],
                  colors=["C0", "C3"], diag1d_kwargs={"colors": ["C0", "C3"]})
  show_input(g, nuisance_params)
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/944ccddd3e9ac0eee9b213f68ec12657661532f8.png]]

** Correlation plot

#+BEGIN_SRC jupyter-python
  g.rectangle_plot(cosmo_params, nuisance_params, roots=samples, filled=True);
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/2a6922f9686cda224b4bbf0145a09220b2615048.png]]

** Write Cls to file
:PROPERTIES:
:HEADER-ARGS: :tangle write_input_cls.py
:END:

#+BEGIN_SRC jupyter-python
  import cobaya
  import camb
  print("      CAMB :", camb.__version__)
  print("    Cobaya :", cobaya.__version__)
#+END_SRC

Set \ell_{max} value
#+BEGIN_SRC jupyter-python :results none
  lmin, lmax = 2, 9000
#+END_SRC

#+BEGIN_SRC jupyter-python :results none
  def write_input_cls(params, out_dir, lmax=lmax, plot=False):
      import os
      os.makedirs(out_dir, exist_ok=True)

      l = np.arange(lmin, lmax)

      # Get CMB Dls from cobaya/camb
      info = {
          "params": params,
          "likelihood": {"mflike.MFLike": {"sim_id": 0, "lmax": lmax}},
          "theory": {"camb": {"extra_args": {"lens_potential_accuracy": 1}}},
          "modules": "/tmp/modules"
      }
      from cobaya.model import get_model
      model = get_model(info)
      Cl = {"tt": lmax, "ee": lmax, "te": lmax, "bb":lmax}
      model.theory["camb"].needs(Cl=Cl)
      model.logposterior({}, cached=False)
      Dls = model.theory["camb"].get_Cl(ell_factor=True)
      dls_cobaya = [Dls[s][lmin:lmax] for s in ["tt", "ee", "bb", "te"]]
      np.savetxt("{}/cosmo_spectra.dat".format(out_dir),
                 np.vstack([l, dls_cobaya]).T)
      mflike = model.likelihood["mflike.MFLike"]
      fg_models = mflike._get_foreground_model(params)
      for k, v in fg_models.items():
          np.savetxt("{}/{}_{}_{}x{}.dat".format(out_dir, *k),
                     np.vstack([l, v]).T)
#+END_SRC

#+BEGIN_SRC jupyter-python
  mean_values = np.mean(pvalues, axis=1)
  fit_cosmo_params = {
      "cosmomc_theta": mean_values[0],
      "As": 1e-10*np.exp(mean_values[1]),
      "ns": mean_values[2],
      "ombh2": mean_values[3],
      "omch2": mean_values[4],
      "Alens": mean_values[6],
      "tau": mean_values[7]
  }
  mean_values = np.mean(nvalues, axis=1)
  fit_nuisance_params = {
      "a_tSZ": mean_values[0],
      "a_kSZ": mean_values[1],
      "a_p": mean_values[2],
      "beta_p": mean_values[3],
      "a_c": mean_values[4],
      "beta_c": mean_values[5],
      "n_CIBC": 1.20,
      "a_s": mean_values[6],
      "T_d": 9.60
  }
  from tabulate import tabulate
  print(tabulate({**fit_cosmo_params, **fit_nuisance_params}.items()))
  write_input_cls(params={**fit_cosmo_params, **fit_nuisance_params},
                  out_dir="/tmp/mflike_fit")
#+END_SRC

#+RESULTS:
#+begin_example
  WARNING:prior:No sampled parameters requested! This will fail for non-mock samplers.
  -------------  -----------
  cosmomc_theta  0.0104088
  As             2.09808e-09
  ns             0.964919
  ombh2          0.022363
  omch2          0.119838
  Alens          1.00245
  tau            0.054402
  a_tSZ          3.31111
  a_kSZ          1.72448
  a_p            6.90229
  beta_p         2.08009
  a_c            4.90854
  beta_c         2.19651
  n_CIBC         1.2
  a_s            3.09908
  T_d            9.6
  -------------  -----------
  [prior] *WARNING* No sampled parameters requested! This will fail for non-mock samplers.
  INFO:camb:Importing *local* CAMB from /tmp/modules/code/CAMB
  [camb] Importing *local* CAMB from /tmp/modules/code/CAMB
  INFO:mflike.mflike:Initialising.
  [mflike.mflike] Initialising.
#+end_example


#+BEGIN_SRC jupyter-python
  input_params = inputs.copy()
  input_params["As"] = 1e-10*np.exp(input_params["logA"])
  del input_params["H0"]
  del input_params["logA"]
  from tabulate import tabulate
  print(tabulate(input_params.items()))
  write_input_cls(params=input_params,
                  out_dir="/tmp/mflike_inputs")
#+END_SRC

#+RESULTS:
#+begin_example
  -------------  ----------
  cosmomc_theta  0.0104085
  ombh2          0.02237
  omch2          0.12
  ns             0.9649
  Alens          1
  tau            0.0544
  a_tSZ          3.30444
  a_kSZ          1.66466
  a_p            6.91247
  beta_p         2.07747
  a_c            4.88618
  beta_c         2.20303
  n_CIBC         1.2
  a_s            3.09921
  T_d            9.6
  As             2.0989e-09
  -------------  ----------
  [prior] *WARNING* No sampled parameters requested! This will fail for non-mock samplers.
  [camb] Importing *local* CAMB from /tmp/modules/code/CAMB
  [mflike.mflike] Initialising.
  get_requirements
  get_requirements
#+end_example

** Check data against MCMC
#+BEGIN_SRC jupyter-python
  data_dir = "/tmp/modules/data"
  cross = (145, 145)
  spectra = ["tt", "te", "tb", "et", "bt", "ee", "eb", "be", "bb"]
  spectrum = "tt"
  index = spectra.index(spectrum)+1
  sims = [np.loadtxt("{}/LAT_MFLike_data/like_products/Dl_LAT_{}xLAT_{}_{:05d}.dat".format(
      data_dir, *cross, i)) for i in range(100)]
  mean_sim = np.mean(sims, axis=0)
  std_sim = np.std(sims, axis=0)/np.sqrt(100)

  Bbl = np.loadtxt("{}/LAT_MFLike_data/like_products/Bbl_LAT_{}xLAT_{}_{}.dat".format(
    data_dir, *cross, spectrum.upper()))
  input_cmb = np.loadtxt("/tmp/mflike_inputs/cosmo_spectra.dat")[:, 1]
  input_fg = np.loadtxt("/tmp/mflike_inputs/{}_all_{}x{}.dat".format(spectrum, *cross))[:, 1]
  input_spec = np.dot(Bbl, input_cmb[:6000]+input_fg[:6000])

  fit_cmb = np.loadtxt("/tmp/mflike_fit/cosmo_spectra.dat")[:, 1]
  fit_fg = np.loadtxt("/tmp/mflike_fit/{}_all_{}x{}.dat".format(spectrum, *cross))[:, 1]
  fit_spec = np.dot(Bbl, fit_cmb[:6000]+fit_fg[:6000])

  import matplotlib.pyplot as plt
  lbin = mean_sim[:, 0]
  plt.plot(lbin, (mean_sim[:, index] - input_spec)/std_sim[:, index], "tab:blue", label="sim - input")
  plt.plot(lbin, (mean_sim[:, index] - fit_spec)/std_sim[:, index], "tab:red", label="sim - fit")

  plt.xlabel("$\ell$")
  plt.ylabel("$\sigma$")
  plt.title("{} - {}x{} GHz".format(spectrum.upper(), *cross))
  plt.legend()
#+END_SRC

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f228207c250>
[[file:./.ob-jupyter/5c76953ec1e8f38f8f910be412af297dfd7013db.png]]
:END:
** Compare version of likelihood
#+BEGIN_SRC jupyter-python
  def show_input(g, params):
      for i, p in enumerate(params):
          x = inputs.get(p, np.nan)
          kwargs = dict(color="gray", ls="--", lw=1)
          for ax in g.subplots[:,i]:
              if ax: ax.axvline(x, **kwargs)
          for ax in g.subplots[i,:i]:
              if ax: ax.axhline(x, **kwargs)

  from getdist.plots import GetDistPlotSettings
  plot_settings = GetDistPlotSettings()
  plot_settings.num_plot_contours = 3
  plot_settings.solid_colors = "tab10"
  plot_settings.line_styles = "tab10"
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  from getdist import loadMCSamples
  sim_id = 1
  sample1 = loadMCSamples("./data/so_likelihood_new/sim_{}/mcmc".format(sim_id),
                          settings={"ignore_rows": 0.4})
  sample2 = loadMCSamples("./data/so_likelihood_norm/sim_{}/mcmc".format(sim_id),
                          settings={"ignore_rows": 0.4})

  from getdist import plots
  g = plots.get_subplot_plotter(settings=plot_settings)
  g.triangle_plot([sample1, sample2], cosmo_params, filled=True,
                  legend_labels=["LAT_MFLike", "LAT_MFLike + norm"],
                  colors=["C0", "C3"], diag1d_kwargs={"colors":["C0", "C3"]})
  # Show input value
  show_input(g, cosmo_params)
  # Show prior on tau
  ax = g.subplots[-1, -1]
  xmin, xmax, ymin, ymax = ax.axis()
  x = np.linspace(xmin, xmax, 100)
  from scipy.stats import norm
  ax.plot(x, 0.018*norm.pdf(x, 0.054, 0.0073), color="gray", ls="--", label=r"$\tau$ prior")
  ax.legend(loc="upper left", bbox_to_anchor=(1,1))
#+END_SRC

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f45c32b2f70>
[[file:./.ob-jupyter/f5ef3b73107ddfc4b07e931fc1de7903df018920.png]]
:END:
